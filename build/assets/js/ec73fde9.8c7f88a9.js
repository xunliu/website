"use strict";(self.webpackChunkdatastrato_next=self.webpackChunkdatastrato_next||[]).push([[4305],{97902:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>d,contentTitle:()=>r,default:()=>h,frontMatter:()=>i,metadata:()=>s,toc:()=>c});var o=a(97458),n=a(37627);const i={title:"Datastrato Origin Story",authors:["JunpingDu"],tags:["company"],slug:"datastrato-origin-story",image:"./2023-12-01-datastrato.png"},r=void 0,s={permalink:"/blog/datastrato-origin-story",source:"@site/blog/2023-12-01-datastrato/index.mdx",title:"Datastrato Origin Story",description:"Datastrato",date:"2023-12-01T00:00:00.000Z",formattedDate:"December 1, 2023",tags:[{label:"company",permalink:"/blog/tags/company"}],readingTime:4.015,hasTruncateMarker:!1,authors:[{name:"Junping Du",title:"CEO",url:"https://github.com/JunpingDu",email:"jp@datastrato.com",imageURL:"https://github.com/JunpingDu.png",key:"JunpingDu"}],frontMatter:{title:"Datastrato Origin Story",authors:["JunpingDu"],tags:["company"],slug:"datastrato-origin-story",image:"./2023-12-01-datastrato.png"},unlisted:!1,prevItem:{title:"We Are Hiring",permalink:"/blog/we-are-hiring"}},d={image:a(22817).Z,authorsImageUrls:[void 0]},c=[{value:"Who are We? Why did we start Datastrato?",id:"who-are-we-why-did-we-start-datastrato",level:2}];function l(e){const t={a:"a",h2:"h2",img:"img",p:"p",...(0,n.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Datastrato",src:a(10198).Z+"",width:"1600",height:"900"})}),"\n",(0,o.jsx)(t.h2,{id:"who-are-we-why-did-we-start-datastrato",children:"Who are We? Why did we start Datastrato?"}),"\n",(0,o.jsxs)(t.p,{children:["I am Junping Du, the Founder and CEO of Datastrato. My long term open source contributions to the ",(0,o.jsx)(t.a,{href:"https://hadoop.apache.org/",children:"Apache Hadoop"})," project enhanced its performance and adaptability within virtualized and cloud-based environments."]}),"\n",(0,o.jsx)(t.p,{children:"My cloud computing odyssey began in 2008 at VMware where I was part of the vCloud Director engineering team. This was a pioneering time in cloud services where AWS was the only option and offered basic services like S3 and EC2, without the advanced features we see today like VPCs. Over the following decade, I saw a shift in application workloads, moving from on-premise data centers to public cloud platforms."}),"\n",(0,o.jsx)(t.p,{children:"In 2010, I turned my focus to data and pioneered VMware\u2019s Hadoop initiatives at a time when Cloudera was just a year old and Hortonworks hadn't emerged yet. During this period, 'Big Data' was synonymous with 'Hadoop', and AWS EMR was still in beta phase. I developed the equivalent of EMR on VMware's platforms like vSphere, vCloud, and CloudFoundry, which included Hadoop Virtualization Extensions (HADOOP-8468) to the Apache Hadoop community, resulting in optimal Hadoop performance in cloud settings used in many organizations today."}),"\n",(0,o.jsx)(t.p,{children:"My passion eventually led me to becoming a lead contributor of Hadoop at Hortonworks in 2014. There I spearheaded the development of Hadoop YARN, a critical infrastructure component of the Hadoop stack. Over the next decade, I observed an increasing trend of data transitioning from private to public cloud environments."}),"\n",(0,o.jsx)(t.p,{children:"In 2018, on the cusp of Hortonworks' merger with Cloudera, I transitioned from Hortonworks to a top-tier global cloud vendor, tasked with developing data warehouse and data lake services from the ground up. This period marked a significant intensification in global cloud market competition. To avoid vendor lock-in and improve their leverage in price negotiations, many companies began adopting a strategy of engaging multiple cloud vendors. While this approach introduced some management complexities, as indicated by third-party reports, it effectively mitigated the risks associated with reliance on a single cloud provider. The growing trend of mergers and acquisitions, along with other international business dynamics, further accelerated the adoption of multi-cloud strategies. The reality of having to deal with multi-cloud environments has become more common as a means of dealing with both complexity and scale."}),"\n",(0,o.jsx)(t.p,{children:"As a result, future data platforms should inherently embrace multi-cloud architecture. This perspective aligns with the ongoing transition of workloads and data from single-cloud environments to more diverse and integrated multi-cloud and hybrid cloud systems. Even today, there are no prominent and effective solutions, whether open source or commercial, for dealing with these environments."}),"\n",(0,o.jsx)(t.p,{children:"Around the same period, I engaged in a thought-provoking dialogue on data and AI innovation with two long-standing colleagues and friends, Jerry Shao and Xun Liu. Jerry, a former colleague at Hortonworks, embarked on his big data journey early at Intel and later emerged as a prominent figure in the Apache Spark community, contributing as a Spark committer and a Project Management Committee (PMC) member at Hortonworks. He is renowned for initiating the Apache Uniffle project, the first stable open-source remote shuffle service, addressing a longstanding challenge in the Spark, MapReduce, and Flink workload ecosystem."}),"\n",(0,o.jsxs)(t.p,{children:["Xun, a longstanding collaborator in the Hadoop community, has worked extensively with me on various projects, including ",(0,o.jsx)(t.a,{href:"https://yunikorn.apache.org/",children:"Apache YuniKorn"}),", Submarine, and others. Today, YuniKorn stands as the de facto standard for deploying data services like Hadoop and Spark on Kubernetes (K8s), thanks to our collaborative efforts and contributions."]}),"\n",(0,o.jsx)(t.p,{children:"Drawing from our shared experiences and insights, we swiftly reached a consensus to embark on an exciting new venture focused on multi-cloud data initiatives. This decision was grounded in our extensive backgrounds and collective wisdom as seasoned data platform engineers."}),"\n",(0,o.jsx)(t.p,{children:"Thus, we, three Apache members (comprising two Hadoop committers and one Spark committer), decided to leave our full-time jobs to delve into the uncharted territories of the data world. Our mission is to dismantle data silos across diverse infrastructures, whether they are multi-cloud, hybrid cloud, or others."}),"\n",(0,o.jsx)(t.p,{children:"We've named our venture \"Data Stratosphere,\" drawing an analogy to the stratosphere, a layer above the clouds where jets soar for smoother travel. Our goal is to offer a similar ease to 'data pilots', eliminating concerns about data isolation and the extra costs associated with multi-cloud adoption. At Datastrato, we aim to provide comprehensive management, governance, analytics, and acceleration for data, addressing the fundamental needs of enterprise data teams."}),"\n",(0,o.jsx)(t.p,{children:"In our vision, Datastrato is more than a company; it's a commitment to smooth, cost-effective data management across diverse cloud infrastructures, guided by our extensive experience and dedication to innovation in the data world."}),"\n",(0,o.jsx)("sub",{children:(0,o.jsx)(t.p,{children:"Apache\xae, Apache Hadoop\xae, Apache Hive\u2122, Apache Iceberg\u2122, Apache Kafka\xae, Apache Spark\u2122,\nApache Submarine\u2122, Apache Thrift\u2122 and Apache Zeppelin\u2122 are either registered trademarks or\ntrademarks of the Apache Software Foundation in the United States and/or other countries."})})]})}function h(e={}){const{wrapper:t}={...(0,n.a)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},22817:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/2023-12-01-datastrato-29cb622c46afb7c47d993189a4ea26ce.png"},10198:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/images/2023-12-01-datastrato-29cb622c46afb7c47d993189a4ea26ce.png"},37627:(e,t,a)=>{a.d(t,{Z:()=>s,a:()=>r});var o=a(52983);const n={},i=o.createContext(n);function r(e){const t=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),o.createElement(i.Provider,{value:t},e.children)}}}]);